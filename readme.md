# Lakehouse Project

## üåü Objectif du projet

Ce projet met en place un **Lakehouse** complet pour le traitement et l'analyse de donn√©es √† grande √©chelle, en utilisant :  

- **Apache Spark** pour le traitement distribu√©.  
- **Apache Iceberg** comme format de table transactionnel sur le lac de donn√©es.  
- **Trino** pour les requ√™tes SQL interactives sur les donn√©es.  
- **Apache Superset** pour la visualisation et le reporting BI.  
- **Terraform** pour provisionner l‚Äôinfrastructure sur AWS.  
- **MinIO** comme stockage S3 compatible local/cloud.  
- **Docker & Docker Compose** pour orchestrer facilement les services.

L‚Äôobjectif est de fournir un environnement **r√©producible**, permettant de tester et d√©ployer des pipelines data de mani√®re modulaire et scalable.

---

## üèó Architecture g√©n√©rale

Voici un sch√©ma simplifi√© de l‚Äôarchitecture :

     +-------------------+
     |  Jupyter Notebook |
     +---------+---------+
               |
               v
     +-------------------+
     |       Spark       |
     | (Docker / Custom)|
     +---------+---------+
               |
               v
     +-------------------+
     |      Iceberg      |
     |     (Tables)      |
     +---------+---------+
               |
               v
     +-------------------+
     |       Trino       |
     |  (Query Engine)   |
     +-------------------+

               |
               v
     +-------------------+
     |      Superset     |
     |     (Dashboard)   |
     +-------------------+

     +-------------------+
     |       MinIO       |
     | (S3 Storage)      |
     +-------------------+



---

## ‚öôÔ∏è Pr√©requis
- **Docker** et **Docker Compose**
- **Terraform** ‚â• 1.5
- **AWS CLI** configur√© avec un profil ayant acc√®s √† VPC, EC2 et Security Groups
- **Python 3.10+** pour les notebooks

---

## üöÄ Installation et lancement

1. **D√©ployer l‚Äôinfrastructure :**
```bash
terraform init
terraform apply
```

2. **D√©marrer les services Docker localement :**

```bash
docker-compose up -d
```

## Si tu as d√©j√† import√© ta key et que tu as cette erreur : 
```bash
InvalidKeyPair.Duplicate: The keypair already exists
```

Fais √ßa puis relance le terraform apply

```bash
aws ec2 delete-key-pair --key-name demo
terraform import aws_key_pair.default demo
```



3. **Acc√©der √† Jupyter Notebook :**

- http://localhost:8888 (Le mot de passe est d√©fini dans le Dockerfile)

## üìö **Utilisation**

Les notebooks Spark se trouvent dans notebooks/ :

Spark.ipynb : introduction et tests Spark

SparkSQL.ipynb : exemples SQL sur Iceberg via Spark

Les configurations Trino et Iceberg sont dans trino/.

Les ressources Terraform dans infra/.

üîí S√©curit√©

Les Security Groups AWS sont configur√©s pour exposer uniquement les ports n√©cessaires :

![Alt text](docs/map.jpg?raw=true "Title")

Les fichiers sensibles comme *.pem, *.tfvars sont exclus du d√©p√¥t via .gitignore.

## üìà **Avantages**

- Environnement reproductible pour tests et d√©veloppement.
- Possibilit√© de scaler Spark et Trino facilement.
- Isolation compl√®te gr√¢ce aux conteneurs Docker.
- Compatible avec AWS et stockage S3 local via MinIO.

## üìé **Quick Reference Commands**
-------------------------------

| **Component** | **Command** |
| --- | --- |
| **Start Services** | `docker-compose up --build -d` |
| **Stop Services** | `docker-compose down` |
| **View Running Containers** | `docker ps` |
| **Check Logs** | `docker-compose logs -f` |
| **Rebuild Containers** | `docker-compose up --build --force-recreate -d` |

* * * * *